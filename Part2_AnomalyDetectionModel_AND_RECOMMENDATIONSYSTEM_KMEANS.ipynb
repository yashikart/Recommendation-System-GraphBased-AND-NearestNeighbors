{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QUeZwQE3968D"
      },
      "id": "QUeZwQE3968D"
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "Anamoly Detection Using\n",
        "\n",
        "*   Local Outlier Factor\n",
        "*   Isolation Forest\n",
        "*   DBSCAN\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "EOKInu_R8hyQ"
      },
      "id": "EOKInu_R8hyQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5bda6506",
      "metadata": {
        "id": "5bda6506",
        "outputId": "6217be51-e5c8-45da-edda-dc9e9f92191d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Anomalous Users Detected by Isolation Forest: 1244\n",
            "Anomalous Users Detected by LOF: 377\n",
            "Anomalous Users Detected by DBSCAN: 14\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "from sklearn.cluster import DBSCAN\n",
        "\n",
        "# Load Data\n",
        "data = pd.read_csv(\"sample30.csv\")\n",
        "\n",
        "# Encode Users\n",
        "user_encoder = LabelEncoder()\n",
        "data['user_id'] = user_encoder.fit_transform(data['reviews_username'].fillna(\"unknown\"))\n",
        "\n",
        "# Handle Missing Values in Numeric Columns\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "data[['reviews_rating', 'reviews_didPurchase', 'reviews_doRecommend']] = imputer.fit_transform(\n",
        "    data[['reviews_rating', 'reviews_didPurchase', 'reviews_doRecommend']])\n",
        "\n",
        "# Aggregate User Behavior\n",
        "user_behavior = data.groupby('user_id').agg(\n",
        "    avg_rating=('reviews_rating', 'mean'),\n",
        "    total_reviews=('user_id', 'count'),\n",
        "    purchase_rate=('reviews_didPurchase', 'mean'),\n",
        "    recommend_rate=('reviews_doRecommend', 'mean')\n",
        ").reset_index()\n",
        "\n",
        "# Normalize Data\n",
        "scaler = StandardScaler()\n",
        "features = ['avg_rating', 'total_reviews', 'purchase_rate', 'recommend_rate']\n",
        "user_behavior[features] = scaler.fit_transform(user_behavior[features])\n",
        "\n",
        "# Anomaly Detection using Isolation Forest\n",
        "iso_forest = IsolationForest(contamination=0.05, random_state=42)\n",
        "user_behavior['iso_anomaly_score'] = iso_forest.fit_predict(user_behavior[features])\n",
        "user_behavior['iso_is_anomalous'] = user_behavior['iso_anomaly_score'] == -1\n",
        "\n",
        "# Anomaly Detection using Local Outlier Factor\n",
        "lof = LocalOutlierFactor(n_neighbors=20, contamination=0.05)\n",
        "user_behavior['lof_anomaly_score'] = lof.fit_predict(user_behavior[features])\n",
        "user_behavior['lof_is_anomalous'] = user_behavior['lof_anomaly_score'] == -1\n",
        "\n",
        "# Anomaly Detection using DBSCAN\n",
        "dbscan = DBSCAN(eps=0.5, min_samples=5)\n",
        "user_behavior['dbscan_labels'] = dbscan.fit_predict(user_behavior[features])\n",
        "user_behavior['dbscan_is_anomalous'] = user_behavior['dbscan_labels'] == -1\n",
        "\n",
        "# Merge Anomaly Data Back to Main Data\n",
        "data = data.merge(user_behavior[['user_id', 'iso_is_anomalous', 'lof_is_anomalous', 'dbscan_is_anomalous']], on='user_id', how='left')\n",
        "\n",
        "# Save Processed Data\n",
        "data.to_csv(\"processed_data.csv\", index=False)\n",
        "\n",
        "# Print Summary\n",
        "print(\"Anomalous Users Detected by Isolation Forest:\", user_behavior['iso_is_anomalous'].sum())\n",
        "print(\"Anomalous Users Detected by LOF:\", user_behavior['lof_is_anomalous'].sum())\n",
        "print(\"Anomalous Users Detected by DBSCAN:\", user_behavior['dbscan_is_anomalous'].sum())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Recommendation System Using KMeans**"
      ],
      "metadata": {
        "id": "jNmjs9tm9FOU"
      },
      "id": "jNmjs9tm9FOU"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d42a7ba5",
      "metadata": {
        "id": "d42a7ba5",
        "outputId": "6cc10c3f-b80a-4b63-fdd9-4e54c1497fd1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Recommended Products: ['Red (special Edition) (dvdvideo)'\n",
            " 'Dark Shadows (includes Digital Copy) (ultraviolet) (dvdvideo)'\n",
            " \"Jason Aldean - They Don't Know\"\n",
            " \"Cheetos Crunchy Flamin' Hot Cheese Flavored Snacks\"\n",
            " 'Smead174 2 1/4 Inch Accordion Expansion Wallet, Poly, Letter, Translucent Green'\n",
            " 'Smead174 Recycled Letter Size Manila File Backs W/prong Fasteners, 2 Capacity, 100/box']\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# Load Data\n",
        "data = pd.read_csv(\"sample30.csv\")\n",
        "\n",
        "# Encode Users\n",
        "user_encoder = LabelEncoder()\n",
        "data['user_id'] = user_encoder.fit_transform(data['reviews_username'])\n",
        "\n",
        "# Encode Products\n",
        "product_encoder = LabelEncoder()\n",
        "data['product_id'] = product_encoder.fit_transform(data['name'])\n",
        "\n",
        "# Compute TF-IDF Vectors for Categories\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "category_tfidf_matrix = tfidf_vectorizer.fit_transform(data['categories'])\n",
        "\n",
        "# Fit Nearest Neighbors Model\n",
        "nn_model = NearestNeighbors(metric='cosine', algorithm='brute')\n",
        "nn_model.fit(category_tfidf_matrix)\n",
        "\n",
        "# Recommendation Function using TF-IDF + Nearest Neighbors\n",
        "def recommend_products(username, num_recommendations=3):\n",
        "    if username not in user_encoder.classes_:\n",
        "        print(\"User not found!\")\n",
        "        return []\n",
        "\n",
        "    user_id = user_encoder.transform([username])[0]\n",
        "    user_products = data[data['user_id'] == user_id]['product_id'].unique()\n",
        "\n",
        "    recommended_items = set()\n",
        "    for product in user_products:\n",
        "        product_idx = np.where(data['product_id'] == product)[0][0]\n",
        "        distances, indices = nn_model.kneighbors(category_tfidf_matrix[product_idx], n_neighbors=num_recommendations+1)\n",
        "        similar_products = data.iloc[indices[0][1:], :]['product_id'].values\n",
        "        recommended_items.update(similar_products)\n",
        "\n",
        "    return product_encoder.inverse_transform(list(recommended_items))\n",
        "\n",
        "# Example Usage\n",
        "recommended_items = recommend_products(\"joshua\")\n",
        "print(\"Recommended Products:\", recommended_items)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8bf37a3d",
      "metadata": {
        "id": "8bf37a3d",
        "outputId": "1fc2bda4-fafd-48c8-8159-04b1adff343c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Joshua's Reviewed Products: ['Pink Friday: Roman Reloaded Re-Up (w/dvd)'\n",
            " 'Dark Shadows (includes Digital Copy) (ultraviolet) (dvdvideo)'\n",
            " 'Red (special Edition) (dvdvideo)'\n",
            " 'Smead174 Recycled Letter Size Manila File Backs W/prong Fasteners, 2 Capacity, 100/box'\n",
            " \"Cheetos Crunchy Flamin' Hot Cheese Flavored Snacks\"]\n"
          ]
        }
      ],
      "source": [
        "user_reviewed_items = data[data['reviews_username'] == \"joshua\"]['name'].unique()\n",
        "print(\"Joshua's Reviewed Products:\", user_reviewed_items)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "33876d71",
      "metadata": {
        "id": "33876d71"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2af3679",
      "metadata": {
        "id": "b2af3679"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "51bf4b7b",
      "metadata": {
        "id": "51bf4b7b"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}